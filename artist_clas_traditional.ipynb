{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load object to artist ID's mapping.\n",
    "import json\n",
    "o2a = open('oid_to_artist_id.json')\n",
    "object_to_artists = json.load(o2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_hog(image):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    image = np.transpose(image, [1,2,0])\n",
    "    hist = hog.compute(image)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "def main(data_path, feature_extractor, max_batches=None):\n",
    "    batch_gen = batch_generator(data_path)\n",
    "    # Load each batch of training data.\n",
    "    train_loss = 0\n",
    "    batch_counter = 0\n",
    "    batch_counter = 0\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(batch_gen)\n",
    "            X, Y = get_array_from_batch(data_path, current_batch, object_to_artists)\n",
    "            X_features = []\n",
    "#             Ys += list(Y)\n",
    "            for i in np.arange(X.shape[0]):\n",
    "                X_features.append(feature_extractor(X[i].astype('uint8')))\n",
    "#             X_features += X_features_curr\n",
    "#             batch_counter += 1\n",
    "#             if (max_batches is not None) and (batch_counter > max_batches):\n",
    "#                 raise(StopIteration)\n",
    "            \n",
    "              \n",
    "#     except StopIteration:\n",
    "#         X_features = np.array(X_features)\n",
    "#         Ys = np.array(Ys)\n",
    "#     return X_features, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "'''\n",
    "Returns an SVM classifier fit to ALL train data points\n",
    "'''\n",
    "def fit_svm(object_to_artists, feature_extractor, max_batches=None):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_path = 'data/train/'\n",
    "    print('Getting training data...')\n",
    "    X, Y = get_all_data(train_path, feature_extractor, max_batches) \n",
    "    X = X.reshape((X.shape[0], -1))\n",
    "    print (X.shape)\n",
    "    clf = LinearSVC()\n",
    "    print('Fitting model...')\n",
    "    clf.fit(X, Y)\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "#     return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(predictor, feature_extractor, data_path, max_batches=None):\n",
    "    X, Y = get_all_data(data_path, feature_extractor, max_batches)\n",
    "    X = X.reshape((X.shape[0], -1))\n",
    "    predictions = predictor.predict(X)\n",
    "    accuracy = float(np.sum(predictions == Y)) / predictions.shape[0]\n",
    "    \n",
    "    print('Accuracy for ' + data_path + ': ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting training data...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-352ead2fefc5>\u001b[0m in \u001b[0;36mget_all_data\u001b[1;34m(data_path, feature_extractor, max_batches)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# Load next batch as NP arrays.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mcurrent_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_array_from_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_to_artists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d547fe0edbd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_to_artists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_hog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_hog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_hog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-38d43b79ddcf>\u001b[0m in \u001b[0;36mfit_svm\u001b[1;34m(object_to_artists, feature_extractor, max_batches)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/train/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting training data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-352ead2fefc5>\u001b[0m in \u001b[0;36mget_all_data\u001b[1;34m(data_path, feature_extractor, max_batches)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mX_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mYs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = fit_svm(object_to_artists, compute_hog, None)\n",
    "predict(clf, compute_hog, 'data/train', None)\n",
    "predict(clf, compute_hog, 'data/test', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
