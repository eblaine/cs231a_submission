{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.misc import imread\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SQUEEZENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "SQUEEZENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load object to artist ID's mapping.\n",
    "import json\n",
    "o2a = open('oid_to_artist_id.json')\n",
    "object_to_artists = json.load(o2a)\n",
    "from utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image processing functions from 231N Assignment 3.\n",
    "def preprocess(img, size=512):\n",
    "    transform = T.Compose([\n",
    "        T.Scale(size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=SQUEEZENET_MEAN.tolist(),\n",
    "                    std=SQUEEZENET_STD.tolist()),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def deprocess(img):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda x: x[0]),\n",
    "        T.Normalize(mean=[0, 0, 0], std=[1.0 / s for s in SQUEEZENET_STD.tolist()]),\n",
    "        T.Normalize(mean=[-m for m in SQUEEZENET_MEAN.tolist()], std=[1, 1, 1]),\n",
    "        T.Lambda(rescale),\n",
    "        T.ToPILImage(),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def rescale(x):\n",
    "    low, high = x.min(), x.max()\n",
    "    x_rescaled = (x - low) / (high - low)\n",
    "    return x_rescaled\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def features_from_img(imgpath, imgsize):\n",
    "    img = preprocess(PIL.Image.open(imgpath), size=imgsize)\n",
    "    img_var = Variable(img.type(dtype))\n",
    "    return extract_features(img_var, cnn), img_var\n",
    "\n",
    "# Older versions of scipy.misc.imresize yield different results\n",
    "# from newer versions, so we check to make sure scipy is up to date.\n",
    "def check_scipy():\n",
    "    import scipy\n",
    "    vnum = int(scipy.__version__.split('.')[1])\n",
    "    assert vnum >= 16, \"You must install SciPy >= 0.16.0 to complete this notebook.\"\n",
    "\n",
    "check_scipy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save default type for GPU.\n",
    "dtype = torch.cuda.FloatTensor \n",
    "num_artists = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained Squeezenet model.\n",
    "cnn = torchvision.models.squeezenet1_1(pretrained=True).features\n",
    "cnn.type(dtype)\n",
    "\n",
    "# Freeze parameters to avoid computation time.\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assignment helper function that takes an image minibatch and model and returns a list of feature maps.\n",
    "def extract_features(x, cnn):\n",
    "    \"\"\"\n",
    "    Use the CNN to extract features from the input image x.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: A PyTorch Variable of shape (N, C, H, W) holding a minibatch of images that\n",
    "      will be fed to the CNN.\n",
    "    - cnn: A PyTorch model that we will use to extract features.\n",
    "    \n",
    "    Returns:\n",
    "    - features: A list of feature for the input images x extracted using the cnn model.\n",
    "      features[i] is a PyTorch Variable of shape (N, C_i, H_i, W_i); recall that features\n",
    "      from different layers of the network may have different numbers of channels (C_i) and\n",
    "      spatial dimensions (H_i, W_i).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    prev_feat = x\n",
    "    for i, module in enumerate(cnn._modules.values()):\n",
    "        next_feat = module(prev_feat)\n",
    "        features.append(next_feat)\n",
    "        prev_feat = next_feat\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Style criterion and classifier.\n",
    "style_criterion = nn.CrossEntropyLoss()\n",
    "#style_classifier = nn.Linear(1548992, num_artists).cuda()\n",
    "style_classifier = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        #nn.Linear(1548992, 256),\n",
    "        nn.Linear(186624, num_artists),\n",
    "        #nn.ReLU(inplace=True),\n",
    "        #nn.Dropout(),\n",
    "        #nn.Linear(256,num_artists)\n",
    "    ).cuda()\n",
    "style_optimizer = torch.optim.Adam(style_classifier.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Content criterion and classifier.\n",
    "content_criterion = nn.CrossEntropyLoss()\n",
    "# content_classifier = nn.Linear(387200, num_artists).cuda()\n",
    "content_classifier = nn.Sequential(\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(387200, num_artists)\n",
    "    ).cuda()\n",
    "content_optimizer = torch.optim.Adam(content_classifier.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to run a single epoch of a model.\n",
    "def run_style_epoch(object_to_artists):\n",
    "    style_train_losses = []\n",
    "    \n",
    "    train_path = 'data/train/'\n",
    "    train_batch_gen = batch_generator(train_path)\n",
    "    # Store indices for style layers and content layer.\n",
    "    #style_layers = [1, 4, 6, 7]\n",
    "    style_layers = [7]\n",
    "    \n",
    "    # Load each batch of training data.\n",
    "    style_train_loss = 0\n",
    "    batch_counter = 0\n",
    "    \n",
    "    # Freeze CNN parameters.\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(train_batch_gen)\n",
    "            X, Y = get_array_from_batch(train_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Store next batch as Torch Variables.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y)).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            \n",
    "            # Extract relevant features of CNN.\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            \n",
    "            style_features_list = []\n",
    "            for idx in style_layers:\n",
    "                style_feats_curr = all_features[idx].clone()\n",
    "                style_feats_curr = style_feats_curr.view(style_feats_curr.size(0), -1) # Flatten current ones\n",
    "                style_features_list.append(style_feats_curr)\n",
    "                \n",
    "            style_features = torch.cat(tuple(style_features_list), 1).cuda()\n",
    "            \n",
    "            # Style: forward.\n",
    "            style_optimizer.zero_grad()\n",
    "            style_output = style_classifier(style_features)\n",
    "            style_loss = style_criterion(style_output, batch_target_var)\n",
    "            \n",
    "            # Style: backward.\n",
    "            style_loss.backward()\n",
    "            style_optimizer.step()\n",
    "            curr_style_loss = style_loss.data[0]\n",
    "            style_train_loss += curr_style_loss\n",
    "        \n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 50  \n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                print('[%5d] Style train loss: %.3f' % (batch_counter, style_train_loss / print_count))\n",
    "                style_train_losses.append(style_train_loss/print_count)\n",
    "                style_train_loss = 0\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    # Load validation data.\n",
    "    val_path = 'data/val/'\n",
    "    val_batch_gen = batch_generator(val_path)\n",
    "    style_val_losses, content_val_losses = [], []\n",
    "    style_val_loss, content_val_loss = 0, 0\n",
    "    batch_counter = 0\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(val_batch_gen)\n",
    "            X, Y = get_array_from_batch(val_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Extract relevant features of CNN.\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            \n",
    "            style_features_list = []\n",
    "            for idx in style_layers:\n",
    "                style_feats_curr = all_features[idx].clone()\n",
    "                style_feats_curr = style_feats_curr.view(style_feats_curr.size(0), -1) # Flatten current ones\n",
    "                style_features_list.append(style_feats_curr)\n",
    "                \n",
    "            style_features = torch.cat(tuple(style_features_list), 1).cuda()\n",
    "            \n",
    "            # Style: forward.\n",
    "            style_optimizer.zero_grad()\n",
    "            style_output = style_classifier(style_features)\n",
    "            style_loss = style_criterion(style_output, batch_target_var)\n",
    "            style_val_loss += style_loss.data[0]\n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 8\n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                print('[%5d] Style val loss: %.3f' % (batch_counter, style_val_loss / print_count))\n",
    "                style_val_losses.append(style_val_loss/print_count)\n",
    "                style_val_loss = 0\n",
    "                      \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return style_train_losses, style_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to run a single epoch of a model.\n",
    "def run_content_epoch(object_to_artists):\n",
    "    content_train_losses = []\n",
    "    \n",
    "    train_path = 'data/train/'\n",
    "    train_batch_gen = batch_generator(train_path)\n",
    "    # Store indices for style layers and content layer.\n",
    "    content_layer = 3\n",
    "    \n",
    "    # Load each batch of training data.\n",
    "    content_train_loss = 0\n",
    "    batch_counter = 0\n",
    "    \n",
    "    # Freeze CNN parameters.\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(train_batch_gen)\n",
    "            X, Y = get_array_from_batch(train_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Store next batch as Torch Variables.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y)).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            \n",
    "            # Extract relevant features of CNN.\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            content_features = all_features[content_layer].clone()\n",
    "            content_features = content_features.view(content_features.size(0), -1).cuda() # Flatten content features\n",
    "\n",
    "            # Content: forward.\n",
    "            content_optimizer.zero_grad()\n",
    "            content_output = content_classifier(content_features)\n",
    "            content_loss = content_criterion(content_output, batch_target_var)\n",
    "            \n",
    "            # Content: backward.\n",
    "            content_loss.backward()\n",
    "            content_optimizer.step()\n",
    "            curr_content_loss = content_loss.data[0]\n",
    "            content_train_loss += curr_content_loss\n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 50  \n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                print('[%5d] Content train loss: %.3f' % (batch_counter, content_train_loss / print_count))\n",
    "                content_train_losses.append(content_train_loss/print_count)\n",
    "                content_train_loss = 0\n",
    "                \n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    # Load validation data.\n",
    "    val_path = 'data/val/'\n",
    "    val_batch_gen = batch_generator(val_path)\n",
    "    content_val_losses = []\n",
    "    content_val_loss = 0\n",
    "    batch_counter = 0\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(val_batch_gen)\n",
    "            X, Y = get_array_from_batch(val_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Extract relevant features of CNN.\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            content_features = all_features[content_layer].clone()\n",
    "            content_features = content_features.view(content_features.size(0), -1).cuda() # Flatten content features\n",
    "            \n",
    "            # Content: forward.\n",
    "            content_optimizer.zero_grad()\n",
    "            content_output = content_classifier(content_features)\n",
    "            content_loss = content_criterion(content_output, batch_target_var)\n",
    "\n",
    "            content_val_loss += content_loss.data[0]\n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 8\n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                \n",
    "                print('[%5d] Content val loss: %.3f' % (batch_counter, content_val_loss / print_count))\n",
    "                content_val_losses.append(content_val_loss/print_count)\n",
    "                content_val_loss = 0\n",
    "                      \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return content_train_losses, content_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to run a single epoch of a model.\n",
    "def run_content_retrain_epoch(object_to_artists):\n",
    "    retrain_content_train_losses = []\n",
    "    \n",
    "    train_path = 'data/train/'\n",
    "    train_batch_gen = batch_generator(train_path)\n",
    "    # Store indices for style layers and content layer.\n",
    "    content_layer = 3\n",
    "    \n",
    "    # Load each batch of training data.\n",
    "    retrain_content_train_loss = 0\n",
    "    batch_counter = 0\n",
    "    \n",
    "    # Retrain CNN and test classification.\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    cnn_optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-5)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(train_batch_gen)\n",
    "            X, Y = get_array_from_batch(train_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Store next batch as Torch Variables.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y)).type(torch.cuda.LongTensor)\n",
    "            \n",
    "#             # Extract relevant features of CNN.\n",
    "            \n",
    "#             all_features = extract_features(batch_input_var_pre, cnn)\n",
    "#             content_features = all_features[content_layer].clone()\n",
    "#             content_features = content_features.view(content_features.size(0), -1).cuda() # Flatten content features\n",
    "\n",
    "            # CNN forward pass.\n",
    "            cnn_optimizer.zero_grad()\n",
    "            cnn_output = cnn(batch_input_var_pre)\n",
    "            cnn_output = cnn_output.view(cnn_output.size(0), -1)\n",
    "            batch_loss = cnn_criterion(cnn_output, batch_target_var)\n",
    "            \n",
    "            # CNN backward pass.\n",
    "            batch_loss.backward()\n",
    "            cnn_optimizer.step()\n",
    "            retrain_content_train_loss += batch_loss.data[0]\n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 50  \n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                print('[%5d] Content train loss: %.3f' % (batch_counter, retrain_content_train_loss / print_count))\n",
    "                retrain_content_train_losses.append(retrain_content_train_loss/print_count)\n",
    "                retrain_content_train_loss = 0\n",
    "                \n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    # Load validation data.\n",
    "    val_path = 'data/val/'\n",
    "    val_batch_gen = batch_generator(val_path)\n",
    "    retrain_content_val_losses = []\n",
    "    retrain_content_val_loss = 0\n",
    "    batch_counter = 0\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(val_batch_gen)\n",
    "            X, Y = get_array_from_batch(val_path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            cnn.eval() \n",
    "\n",
    "            # CNN forward pass.\n",
    "            cnn_optimizer.zero_grad()\n",
    "            cnn_output = cnn(batch_input_var_pre)\n",
    "            cnn_output = cnn_output.view(cnn_output.size(0), -1)\n",
    "            batch_loss = cnn_criterion(cnn_output, batch_target_var)\n",
    "            \n",
    "            retrain_content_val_loss += batch_loss.data[0]\n",
    "            \n",
    "            # Print loss.\n",
    "            batch_counter += 1\n",
    "            print_count = 8\n",
    "            \n",
    "            if batch_counter % print_count == 0: # Print avg batch loss, every 100 mini-batches. Zero out.\n",
    "                \n",
    "                print('[%5d] Content val loss: %.3f' % (batch_counter, retrain_content_val_loss / print_count))\n",
    "                retrain_content_val_losses.append(retrain_content_val_loss/print_count)\n",
    "                retrain_content_val_loss = 0\n",
    "                      \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return retrain_content_train_losses, retrain_content_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_style_accuracy(atype, object_to_artists):\n",
    "    path = 'data/' + atype \n",
    "    batch_gen = batch_generator(path)\n",
    "    num_predictions = 0\n",
    "    num_correct_predictions = 0\n",
    "    batch_size = 50\n",
    "    batch_counter = 0\n",
    "    train_batches = 100\n",
    "\n",
    "    # style_layers = [1, 4, 6, 7]\n",
    "    style_layers = [7]\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(batch_gen)\n",
    "            X, Y = get_array_from_batch(path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), volatile=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Make content predictions\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            \n",
    "            style_features_list = []\n",
    "            for idx in style_layers:\n",
    "                style_feats_curr = all_features[idx].clone()\n",
    "                style_feats_curr = style_feats_curr.view(style_feats_curr.size(0), -1) # Flatten current ones\n",
    "                style_features_list.append(style_feats_curr)\n",
    "                \n",
    "            style_features = torch.cat(tuple(style_features_list), 1).cuda()\n",
    "            \n",
    "            style_output = style_classifier(style_features)\n",
    "            predictions = torch.max(style_output, 1)[1]\n",
    "            \n",
    "            # Check accuracy\n",
    "            num_predictions += 50\n",
    "            num_correct_predictions += torch.sum(torch.eq(predictions, batch_target_var)).data[0]\n",
    "            \n",
    "            batch_counter += 1\n",
    "            if batch_counter == train_batches and atype == 'train':\n",
    "                raise(StopIteration)\n",
    "            \n",
    "                      \n",
    "    except StopIteration:\n",
    "        accuracy = float(num_correct_predictions) / num_predictions\n",
    "        print(atype + ' accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_content_accuracy(atype, object_to_artists):\n",
    "    path = 'data/' + atype \n",
    "    batch_gen = batch_generator(path)\n",
    "    num_predictions = 0\n",
    "    num_correct_predictions = 0\n",
    "    batch_size = 50\n",
    "    batch_counter = 0\n",
    "    train_batches = 100\n",
    "\n",
    "    content_layer = 3\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(batch_gen)\n",
    "            X, Y = get_array_from_batch(path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), volatile=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Make content predictions\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            content_features = all_features[content_layer].clone()\n",
    "            content_features = content_features.view(content_features.size(0), -1).cuda() # Flatten content features\n",
    "            \n",
    "            content_output = content_classifier(content_features)\n",
    "            predictions = torch.max(content_output, 1)[1]\n",
    "            \n",
    "            # Check accuracy\n",
    "            num_predictions += 50\n",
    "            num_correct_predictions += torch.sum(torch.eq(predictions, batch_target_var)).data[0]\n",
    "            \n",
    "            batch_counter += 1\n",
    "            if batch_counter == train_batches and atype == 'train':\n",
    "                raise(StopIteration)\n",
    "            \n",
    "                      \n",
    "    except StopIteration:\n",
    "        accuracy = float(num_correct_predictions) / num_predictions\n",
    "        print(atype + ' accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply content classifier.\n",
    "new_classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Conv2d(512, num_artists, kernel_size=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(13)\n",
    ").cuda()\n",
    "\n",
    "content_train_losses, content_val_losses = [], []\n",
    "retrain_content_train_losses, retrain_content_val_losses = [], []\n",
    "\n",
    "content_optimizer = torch.optim.Adam(content_classifier.parameters(), lr = 1e-3)\n",
    "\n",
    "for j in range(5):\n",
    "    content_optimizer = torch.optim.Adam(content_classifier.parameters(), lr = 1e-3)\n",
    "    for i in range(5):\n",
    "        print('Epoch: ' + str(i+1))\n",
    "        curr_content_tl, curr_content_vl = run_content_epoch(object_to_artists)\n",
    "        content_train_losses += curr_content_tl\n",
    "        content_val_losses += curr_content_vl\n",
    "        compute_content_accuracy('train', object_to_artists)\n",
    "        compute_content_accuracy('test', object_to_artists)\n",
    "\n",
    "    # Retrain CNN and test classification.\n",
    "    cnn.classifier = new_classifier\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    content_optimizer = torch.optim.Adam(content_classifier.parameters(), lr = 1e-4)\n",
    "    print('Starting Retraining Cycle.')\n",
    "\n",
    "    for i in range(5):\n",
    "        curr_content_tl, curr_content_vl = run_content_retrain_epoch(object_to_artists)\n",
    "        retrain_content_train_losses += curr_content_tl\n",
    "        retrain_content_val_losses += curr_content_vl\n",
    "\n",
    "        compute_content_accuracy('train', object_to_artists)\n",
    "        compute_content_accuracy('test', object_to_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_content_predictions(n_batches, atype, object_to_artists):\n",
    "    path = 'data/' + atype \n",
    "    batch_gen = batch_generator(path)\n",
    "    \n",
    "    all_predictions = np.zeros((50 * n_batches))\n",
    "    all_labels = np.zeros((50 * n_batches))\n",
    "    batch_counter = 0\n",
    "    \n",
    "    content_layer = 3\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(batch_gen)\n",
    "            X, Y = get_array_from_batch(path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), volatile=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Make predictions\n",
    "#             batch_output = model(batch_input_var_pre)\n",
    "            \n",
    "            # Make content predictions\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            content_features = all_features[content_layer].clone()\n",
    "            content_features = content_features.view(content_features.size(0), -1).cuda() # Flatten content features\n",
    "            \n",
    "            content_output = content_classifier(content_features)\n",
    "            \n",
    "            predictions = torch.max(content_output, 1)[1]\n",
    "            predictions = predictions.view(predictions.size(0))\n",
    "            start = batch_counter * 50\n",
    "            all_predictions[start:start + 50] = predictions.data.cpu().numpy()\n",
    "            all_labels[start:start + 50] = Y\n",
    "            \n",
    "            batch_counter += 1\n",
    "            if batch_counter == n_batches:\n",
    "                raise(StopIteration)\n",
    "                      \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_content_confusion_matrix(n_categories, n_batches, atype, object_to_artists):\n",
    "    confusion = torch.zeros(n_categories, n_categories)\n",
    "    \n",
    "    predictions, labels = generate_content_predictions(n_batches, atype, object_to_artists)\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        prediction = predictions[i]\n",
    "        label = labels[i]\n",
    "        confusion[label][prediction] += 1\n",
    "    \n",
    "    \n",
    "    # Normalize by dividing every row by its sum\n",
    "    for i in range(n_categories):\n",
    "        confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "    # Set up plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion.numpy())\n",
    "    fig.colorbar(cax, cmap='jet')\n",
    "\n",
    "    # Set up axes\n",
    "    all_categories = ['Jan Luyken',\n",
    "        'George Breitner',\n",
    "        'Reinier Vinkeles',\n",
    "        'Marius Bauer',\n",
    "        'Isaac Israels',\n",
    "        'Willem Witsen',\n",
    "        'Daniel Chodowiecki',\n",
    "        'Bernard Picart',\n",
    "        'Rembrandt van Rijn',\n",
    "        'Jacob Houbraken',\n",
    "        'Antonio Tempesta',\n",
    "        'Johannes Tavenraat',\n",
    "        'Wenceslaus Hollar',\n",
    "        'Simon Fokke',\n",
    "        'Carel Cachet',\n",
    "        'Jacob de Gheyn (II)',\n",
    "        'Romeyn de Hooghe',\n",
    "        'Meissener Manufaktur',\n",
    "        'Jacques Callot',\n",
    "        'Johann Sadeler (I)',\n",
    "        'Jozef Israels',\n",
    "        'Frans Hogenberg',\n",
    "        'Crispijn van de Passe',\n",
    "        'Jan van de Velde (II)',\n",
    "        'Virgilius Solis (I)']\n",
    "    ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "    ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "    # Force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    # sphinx_gallery_thumbnail_number = 2\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_content_confusion_matrix(25, 100, 'test', object_to_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Linear Layers, Cycle 1\n",
      "Epoch: 1\n",
      "[   50] Style train loss: 541.712\n",
      "[  100] Style train loss: 328.861\n",
      "[  150] Style train loss: 259.758\n",
      "[    8] Style val loss: 240.804\n",
      "[   16] Style val loss: 224.291\n",
      "[   24] Style val loss: 256.082\n",
      "train accuracy: 0.5752\n",
      "test accuracy: 0.44456140350877194\n",
      "Epoch: 2\n",
      "[   50] Style train loss: 133.878\n",
      "[  100] Style train loss: 155.840\n",
      "[  150] Style train loss: 138.640\n",
      "[    8] Style val loss: 205.259\n",
      "[   16] Style val loss: 203.488\n",
      "[   24] Style val loss: 194.102\n",
      "train accuracy: 0.703\n",
      "test accuracy: 0.5196491228070176\n",
      "Epoch: 3\n",
      "[   50] Style train loss: 70.195\n",
      "[  100] Style train loss: 88.384\n",
      "[  150] Style train loss: 70.101\n",
      "[    8] Style val loss: 151.810\n",
      "[   16] Style val loss: 163.295\n",
      "[   24] Style val loss: 180.768\n",
      "train accuracy: 0.793\n",
      "test accuracy: 0.5185964912280702\n",
      "Epoch: 4\n",
      "[   50] Style train loss: 54.655\n",
      "[  100] Style train loss: 65.210\n",
      "[  150] Style train loss: 59.867\n",
      "[    8] Style val loss: 198.622\n",
      "[   16] Style val loss: 191.006\n",
      "[   24] Style val loss: 171.599\n",
      "train accuracy: 0.8452\n",
      "test accuracy: 0.5505263157894736\n",
      "Epoch: 5\n",
      "[   50] Style train loss: 30.053\n",
      "[  100] Style train loss: 49.364\n",
      "[  150] Style train loss: 40.589\n",
      "[    8] Style val loss: 218.667\n",
      "[   16] Style val loss: 269.454\n",
      "[   24] Style val loss: 242.479\n",
      "train accuracy: 0.8004\n",
      "test accuracy: 0.4957894736842105\n",
      "Starting Retraining Cycle 1\n",
      "[   50] Content train loss: 3.304\n",
      "[  100] Content train loss: 3.035\n",
      "[  150] Content train loss: 2.864\n",
      "[    8] Content val loss: 2.651\n",
      "[   16] Content val loss: 2.593\n",
      "[   24] Content val loss: 2.642\n",
      "train accuracy: 0.7664\n",
      "test accuracy: 0.5091228070175439\n",
      "[   50] Content train loss: 2.583\n",
      "[  100] Content train loss: 2.484\n",
      "[  150] Content train loss: 2.279\n",
      "[    8] Content val loss: 2.222\n",
      "[   16] Content val loss: 2.291\n",
      "[   24] Content val loss: 2.341\n",
      "train accuracy: 0.7304\n",
      "test accuracy: 0.4691228070175439\n",
      "[   50] Content train loss: 2.297\n",
      "[  100] Content train loss: 2.121\n",
      "[  150] Content train loss: 2.138\n",
      "[    8] Content val loss: 2.040\n",
      "[   16] Content val loss: 1.937\n",
      "[   24] Content val loss: 2.218\n",
      "train accuracy: 0.716\n",
      "test accuracy: 0.46771929824561403\n",
      "[   50] Content train loss: 1.998\n",
      "[  100] Content train loss: 2.001\n",
      "[  150] Content train loss: 1.949\n",
      "[    8] Content val loss: 1.832\n",
      "[   16] Content val loss: 1.892\n",
      "[   24] Content val loss: 1.898\n",
      "train accuracy: 0.7064\n",
      "test accuracy: 0.46421052631578946\n",
      "[   50] Content train loss: 1.884\n",
      "[  100] Content train loss: 1.808\n",
      "[  150] Content train loss: 1.809\n",
      "[    8] Content val loss: 1.912\n",
      "[   16] Content val loss: 1.797\n",
      "[   24] Content val loss: 1.639\n",
      "train accuracy: 0.7166\n",
      "test accuracy: 0.46771929824561403\n",
      "Retraining Linear Layers, Cycle 2\n",
      "Epoch: 1\n",
      "[   50] Style train loss: 110.421\n",
      "[  100] Style train loss: 63.516\n",
      "[  150] Style train loss: 73.089\n",
      "[    8] Style val loss: 355.006\n",
      "[   16] Style val loss: 352.011\n",
      "[   24] Style val loss: 345.260\n",
      "train accuracy: 0.7908\n",
      "test accuracy: 0.535438596491228\n",
      "Epoch: 2\n",
      "[   50] Style train loss: 60.129\n",
      "[  100] Style train loss: 50.610\n",
      "[  150] Style train loss: 59.226\n",
      "[    8] Style val loss: 279.715\n",
      "[   16] Style val loss: 272.627\n",
      "[   24] Style val loss: 256.615\n",
      "train accuracy: 0.873\n",
      "test accuracy: 0.5856140350877193\n",
      "Epoch: 3\n",
      "[   50] Style train loss: 42.620\n",
      "[  100] Style train loss: 42.176\n",
      "[  150] Style train loss: 48.258\n",
      "[    8] Style val loss: 247.807\n",
      "[   16] Style val loss: 308.922\n",
      "[   24] Style val loss: 278.386\n",
      "train accuracy: 0.8826\n",
      "test accuracy: 0.5736842105263158\n",
      "Epoch: 4\n",
      "[   50] Style train loss: 42.388\n",
      "[  100] Style train loss: 47.710\n",
      "[  150] Style train loss: 41.902\n",
      "[    8] Style val loss: 462.612\n",
      "[   16] Style val loss: 411.836\n",
      "[   24] Style val loss: 405.490\n",
      "train accuracy: 0.807\n",
      "test accuracy: 0.5280701754385965\n",
      "Epoch: 5\n",
      "[   50] Style train loss: 81.759\n",
      "[  100] Style train loss: 43.544\n",
      "[  150] Style train loss: 41.608\n",
      "[    8] Style val loss: 277.376\n",
      "[   16] Style val loss: 274.598\n",
      "[   24] Style val loss: 301.168\n",
      "train accuracy: 0.9102\n",
      "test accuracy: 0.5954385964912281\n",
      "Starting Retraining Cycle 2\n",
      "[   50] Content train loss: 1.772\n",
      "[  100] Content train loss: 1.751\n",
      "[  150] Content train loss: 1.736\n",
      "[    8] Content val loss: 1.795\n",
      "[   16] Content val loss: 1.738\n",
      "[   24] Content val loss: 1.714\n",
      "train accuracy: 0.9254\n",
      "test accuracy: 0.6028070175438597\n",
      "[   50] Content train loss: 1.593\n",
      "[  100] Content train loss: 1.718\n",
      "[  150] Content train loss: 1.671\n",
      "[    8] Content val loss: 1.624\n",
      "[   16] Content val loss: 1.643\n",
      "[   24] Content val loss: 1.804\n",
      "train accuracy: 0.9044\n",
      "test accuracy: 0.5880701754385965\n",
      "[   50] Content train loss: 1.645\n",
      "[  100] Content train loss: 1.614\n",
      "[  150] Content train loss: 1.598\n",
      "[    8] Content val loss: 1.693\n",
      "[   16] Content val loss: 1.595\n",
      "[   24] Content val loss: 1.600\n",
      "train accuracy: 0.9098\n",
      "test accuracy: 0.6003508771929824\n",
      "[   50] Content train loss: 1.565\n",
      "[  100] Content train loss: 1.565\n",
      "[  150] Content train loss: 1.523\n",
      "[    8] Content val loss: 1.583\n",
      "[   16] Content val loss: 1.493\n",
      "[   24] Content val loss: 1.635\n",
      "train accuracy: 0.9094\n",
      "test accuracy: 0.6021052631578947\n",
      "[   50] Content train loss: 1.498\n",
      "[  100] Content train loss: 1.484\n",
      "[  150] Content train loss: 1.512\n",
      "[    8] Content val loss: 1.511\n",
      "[   16] Content val loss: 1.815\n",
      "[   24] Content val loss: 1.585\n",
      "train accuracy: 0.9016\n",
      "test accuracy: 0.5936842105263158\n",
      "Retraining Linear Layers, Cycle 3\n",
      "Epoch: 1\n",
      "[   50] Style train loss: 54.379\n",
      "[  100] Style train loss: 46.997\n",
      "[  150] Style train loss: 44.508\n",
      "[    8] Style val loss: 317.294\n",
      "[   16] Style val loss: 389.014\n",
      "[   24] Style val loss: 308.384\n",
      "train accuracy: 0.9144\n",
      "test accuracy: 0.5975438596491228\n",
      "Epoch: 2\n",
      "[   50] Style train loss: 35.651\n",
      "[  100] Style train loss: 33.317\n",
      "[  150] Style train loss: 40.696\n",
      "[    8] Style val loss: 247.385\n",
      "[   16] Style val loss: 394.910\n",
      "[   24] Style val loss: 295.611\n",
      "train accuracy: 0.9146\n",
      "test accuracy: 0.5821052631578948\n",
      "Epoch: 3\n",
      "[   50] Style train loss: 44.274\n",
      "[  100] Style train loss: 61.983\n",
      "[  150] Style train loss: 66.818\n",
      "[    8] Style val loss: 351.902\n",
      "[   16] Style val loss: 381.354\n",
      "[   24] Style val loss: 375.022\n",
      "train accuracy: 0.9212\n",
      "test accuracy: 0.5982456140350877\n",
      "Epoch: 4\n",
      "[   50] Style train loss: 23.576\n",
      "[  100] Style train loss: 31.552\n",
      "[  150] Style train loss: 27.769\n",
      "[    8] Style val loss: 351.990\n",
      "[   16] Style val loss: 317.981\n",
      "[   24] Style val loss: 351.523\n",
      "train accuracy: 0.9382\n",
      "test accuracy: 0.5971929824561404\n",
      "Epoch: 5\n",
      "[   50] Style train loss: 33.124\n",
      "[  100] Style train loss: 28.292\n",
      "[  150] Style train loss: 30.635\n",
      "[    8] Style val loss: 415.594\n",
      "[   16] Style val loss: 436.102\n",
      "[   24] Style val loss: 359.756\n",
      "train accuracy: 0.8966\n",
      "test accuracy: 0.5642105263157895\n",
      "Starting Retraining Cycle 3\n",
      "[   50] Content train loss: 1.492\n",
      "[  100] Content train loss: 1.443\n",
      "[  150] Content train loss: 1.401\n",
      "[    8] Content val loss: 1.548\n",
      "[   16] Content val loss: 1.458\n",
      "[   24] Content val loss: 1.537\n",
      "train accuracy: 0.891\n",
      "test accuracy: 0.5673684210526316\n",
      "[   50] Content train loss: 1.351\n",
      "[  100] Content train loss: 1.412\n",
      "[  150] Content train loss: 1.423\n",
      "[    8] Content val loss: 1.433\n",
      "[   16] Content val loss: 1.461\n",
      "[   24] Content val loss: 1.476\n",
      "train accuracy: 0.8986\n",
      "test accuracy: 0.5768421052631579\n",
      "[   50] Content train loss: 1.344\n",
      "[  100] Content train loss: 1.399\n",
      "[  150] Content train loss: 1.370\n",
      "[    8] Content val loss: 1.427\n",
      "[   16] Content val loss: 1.494\n",
      "[   24] Content val loss: 1.445\n",
      "train accuracy: 0.888\n",
      "test accuracy: 0.5659649122807018\n",
      "[   50] Content train loss: 1.331\n",
      "[  100] Content train loss: 1.287\n",
      "[  150] Content train loss: 1.348\n",
      "[    8] Content val loss: 1.563\n",
      "[   16] Content val loss: 1.339\n",
      "[   24] Content val loss: 1.594\n",
      "train accuracy: 0.8978\n",
      "test accuracy: 0.5754385964912281\n",
      "[   50] Content train loss: 1.300\n",
      "[  100] Content train loss: 1.302\n",
      "[  150] Content train loss: 1.310\n",
      "[    8] Content val loss: 1.346\n",
      "[   16] Content val loss: 1.490\n",
      "[   24] Content val loss: 1.373\n",
      "train accuracy: 0.894\n",
      "test accuracy: 0.5694736842105264\n",
      "Retraining Linear Layers, Cycle 4\n",
      "Epoch: 1\n",
      "[   50] Style train loss: 55.630\n",
      "[  100] Style train loss: 39.487\n",
      "[  150] Style train loss: 29.276\n",
      "[    8] Style val loss: 431.427\n",
      "[   16] Style val loss: 428.950\n",
      "[   24] Style val loss: 401.172\n",
      "train accuracy: 0.9238\n",
      "test accuracy: 0.5750877192982456\n",
      "Epoch: 2\n",
      "[   50] Style train loss: 38.033\n",
      "[  100] Style train loss: 29.452\n",
      "[  150] Style train loss: 29.707\n",
      "[    8] Style val loss: 411.993\n",
      "[   16] Style val loss: 375.249\n",
      "[   24] Style val loss: 420.816\n",
      "train accuracy: 0.9248\n",
      "test accuracy: 0.5740350877192982\n",
      "Epoch: 3\n",
      "[   50] Style train loss: 29.914\n",
      "[  100] Style train loss: 22.141\n",
      "[  150] Style train loss: 32.328\n",
      "[    8] Style val loss: 483.814\n",
      "[   16] Style val loss: 484.378\n",
      "[   24] Style val loss: 468.140\n",
      "train accuracy: 0.9198\n",
      "test accuracy: 0.5954385964912281\n",
      "Epoch: 4\n",
      "[   50] Style train loss: 23.068\n",
      "[  100] Style train loss: 29.483\n",
      "[  150] Style train loss: 42.360\n",
      "[    8] Style val loss: 406.058\n",
      "[   16] Style val loss: 431.308\n",
      "[   24] Style val loss: 461.289\n",
      "train accuracy: 0.9438\n",
      "test accuracy: 0.6119298245614035\n",
      "Epoch: 5\n",
      "[   50] Style train loss: 41.934\n",
      "[  100] Style train loss: 33.666\n",
      "[  150] Style train loss: 33.826\n",
      "[    8] Style val loss: 464.408\n",
      "[   16] Style val loss: 483.532\n",
      "[   24] Style val loss: 586.783\n",
      "train accuracy: 0.923\n",
      "test accuracy: 0.5968421052631578\n",
      "Starting Retraining Cycle 4\n",
      "[   50] Content train loss: 1.303\n",
      "[  100] Content train loss: 1.308\n",
      "[  150] Content train loss: 1.267\n",
      "[    8] Content val loss: 1.346\n",
      "[   16] Content val loss: 1.437\n",
      "[   24] Content val loss: 1.278\n",
      "train accuracy: 0.9242\n",
      "test accuracy: 0.583859649122807\n",
      "[   50] Content train loss: 1.229\n",
      "[  100] Content train loss: 1.245\n",
      "[  150] Content train loss: 1.216\n",
      "[    8] Content val loss: 1.375\n",
      "[   16] Content val loss: 1.527\n",
      "[   24] Content val loss: 1.241\n",
      "train accuracy: 0.9228\n",
      "test accuracy: 0.5936842105263158\n",
      "[   50] Content train loss: 1.237\n",
      "[  100] Content train loss: 1.299\n",
      "[  150] Content train loss: 1.198\n",
      "[    8] Content val loss: 1.448\n",
      "[   16] Content val loss: 1.261\n",
      "[   24] Content val loss: 1.265\n",
      "train accuracy: 0.922\n",
      "test accuracy: 0.5919298245614035\n",
      "[   50] Content train loss: 1.172\n",
      "[  100] Content train loss: 1.208\n",
      "[  150] Content train loss: 1.195\n",
      "[    8] Content val loss: 1.312\n",
      "[   16] Content val loss: 1.267\n",
      "[   24] Content val loss: 1.423\n",
      "train accuracy: 0.9252\n",
      "test accuracy: 0.6010526315789474\n",
      "[   50] Content train loss: 1.210\n",
      "[  100] Content train loss: 1.125\n",
      "[  150] Content train loss: 1.133\n",
      "[    8] Content val loss: 1.317\n",
      "[   16] Content val loss: 1.318\n",
      "[   24] Content val loss: 1.278\n",
      "train accuracy: 0.9258\n",
      "test accuracy: 0.5933333333333334\n",
      "Retraining Linear Layers, Cycle 5\n",
      "Epoch: 1\n",
      "[   50] Style train loss: 24.253\n",
      "[  100] Style train loss: 30.503\n",
      "[  150] Style train loss: 28.147\n",
      "[    8] Style val loss: 738.581\n",
      "[   16] Style val loss: 612.402\n",
      "[   24] Style val loss: 764.805\n",
      "train accuracy: 0.8362\n",
      "test accuracy: 0.5168421052631579\n",
      "Epoch: 2\n",
      "[   50] Style train loss: 55.474\n",
      "[  100] Style train loss: 52.027\n",
      "[  150] Style train loss: 28.139\n",
      "[    8] Style val loss: 487.941\n",
      "[   16] Style val loss: 492.322\n",
      "[   24] Style val loss: 405.929\n",
      "train accuracy: 0.9458\n",
      "test accuracy: 0.6178947368421053\n",
      "Epoch: 3\n",
      "[   50] Style train loss: 43.564\n",
      "[  100] Style train loss: 35.279\n",
      "[  150] Style train loss: 38.353\n",
      "[    8] Style val loss: 435.693\n",
      "[   16] Style val loss: 596.106\n",
      "[   24] Style val loss: 494.675\n",
      "train accuracy: 0.9418\n",
      "test accuracy: 0.5985964912280701\n",
      "Epoch: 4\n",
      "[   50] Style train loss: 16.185\n",
      "[  100] Style train loss: 21.160\n",
      "[  150] Style train loss: 26.627\n",
      "[    8] Style val loss: 407.321\n",
      "[   16] Style val loss: 554.584\n",
      "[   24] Style val loss: 473.403\n",
      "train accuracy: 0.9578\n",
      "test accuracy: 0.6112280701754386\n",
      "Epoch: 5\n",
      "[   50] Style train loss: 23.580\n",
      "[  100] Style train loss: 16.686\n",
      "[  150] Style train loss: 26.159\n",
      "[    8] Style val loss: 453.429\n",
      "[   16] Style val loss: 416.355\n",
      "[   24] Style val loss: 463.393\n",
      "train accuracy: 0.9768\n",
      "test accuracy: 0.6371929824561403\n",
      "Starting Retraining Cycle 5\n",
      "[   50] Content train loss: 1.163\n",
      "[  100] Content train loss: 1.120\n",
      "[  150] Content train loss: 1.155\n",
      "[    8] Content val loss: 1.350\n",
      "[   16] Content val loss: 1.327\n",
      "[   24] Content val loss: 1.195\n",
      "train accuracy: 0.9752\n",
      "test accuracy: 0.6273684210526316\n",
      "[   50] Content train loss: 1.150\n",
      "[  100] Content train loss: 1.102\n",
      "[  150] Content train loss: 1.123\n",
      "[    8] Content val loss: 1.278\n",
      "[   16] Content val loss: 1.192\n",
      "[   24] Content val loss: 1.327\n",
      "train accuracy: 0.9788\n",
      "test accuracy: 0.6378947368421053\n",
      "[   50] Content train loss: 1.083\n",
      "[  100] Content train loss: 1.093\n",
      "[  150] Content train loss: 1.113\n",
      "[    8] Content val loss: 1.255\n",
      "[   16] Content val loss: 1.340\n",
      "[   24] Content val loss: 1.284\n",
      "train accuracy: 0.9744\n",
      "test accuracy: 0.6364912280701754\n",
      "[   50] Content train loss: 1.112\n",
      "[  100] Content train loss: 1.041\n",
      "[  150] Content train loss: 1.087\n",
      "[    8] Content val loss: 1.277\n",
      "[   16] Content val loss: 1.308\n",
      "[   24] Content val loss: 1.252\n",
      "train accuracy: 0.9776\n",
      "test accuracy: 0.6396491228070176\n",
      "[   50] Content train loss: 1.074\n",
      "[  100] Content train loss: 1.074\n",
      "[  150] Content train loss: 1.053\n",
      "[    8] Content val loss: 1.186\n",
      "[   16] Content val loss: 1.246\n",
      "[   24] Content val loss: 1.305\n",
      "train accuracy: 0.9742\n",
      "test accuracy: 0.6350877192982456\n"
     ]
    }
   ],
   "source": [
    "# Apply style classifier.\n",
    "new_classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Conv2d(512, num_artists, kernel_size=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(13)\n",
    ").cuda()\n",
    "\n",
    "style_train_losses, style_val_losses = [], []\n",
    "retrain_style_train_losses, retrain_style_val_losses = [], []\n",
    "\n",
    "style_optimizer = torch.optim.Adam(style_classifier.parameters(), lr = 1e-3)\n",
    "\n",
    "for j in range(5):\n",
    "    print('Retraining Linear Layers, Cycle ' + str(j+1))\n",
    "    style_optimizer = torch.optim.Adam(style_classifier.parameters(), lr = 1e-3)\n",
    "    for i in range(5):\n",
    "        print('Epoch: ' + str(i+1))\n",
    "        curr_style_tl, curr_style_vl = run_style_epoch(object_to_artists)\n",
    "        style_train_losses += curr_style_tl\n",
    "        style_val_losses += curr_style_vl\n",
    "        compute_style_accuracy('train', object_to_artists)\n",
    "        compute_style_accuracy('test', object_to_artists)\n",
    "\n",
    "    # Retrain CNN and test classification.\n",
    "    cnn.classifier = new_classifier\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    style_optimizer = torch.optim.Adam(style_classifier.parameters(), lr = 1e-4)\n",
    "    print('Starting Retraining Cycle ' + str(j+1))\n",
    "\n",
    "    for i in range(5):\n",
    "        curr_style_tl, curr_style_vl = run_content_retrain_epoch(object_to_artists)\n",
    "        retrain_style_train_losses += curr_style_tl\n",
    "        retrain_style_val_losses += curr_style_vl\n",
    "\n",
    "        compute_style_accuracy('train', object_to_artists)\n",
    "        compute_style_accuracy('test', object_to_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate style predictions\n",
    "def generate_style_predictions(n_batches, atype, object_to_artists):\n",
    "    path = 'data/' + atype \n",
    "    batch_gen = batch_generator(path)\n",
    "    \n",
    "    all_predictions = np.zeros((50 * n_batches))\n",
    "    all_labels = np.zeros((50 * n_batches))\n",
    "    batch_counter = 0\n",
    "    \n",
    "    # content_layer = 3\n",
    "    style_layer = 7\n",
    "    try:\n",
    "        while True:\n",
    "            # Load next batch as NP arrays.\n",
    "            current_batch = next(batch_gen)\n",
    "            X, Y = get_array_from_batch(path, current_batch, object_to_artists)\n",
    "            \n",
    "            # Forward pass.\n",
    "            batch_input_var = torch.autograd.Variable(torch.from_numpy(X), volatile=True).type(torch.cuda.FloatTensor)\n",
    "            preprocessor = torch.nn.BatchNorm2d(3).cuda()\n",
    "            batch_input_pre = preprocessor(batch_input_var)\n",
    "            batch_input_var_pre = torch.autograd.Variable(batch_input_pre.data, requires_grad=True).type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            batch_target_var = torch.autograd.Variable(torch.from_numpy(Y), volatile=True).type(torch.cuda.LongTensor)\n",
    "            \n",
    "            # Make predictions\n",
    "#             batch_output = model(batch_input_var_pre)\n",
    "            \n",
    "            # Make content predictions\n",
    "            all_features = extract_features(batch_input_var_pre, cnn)\n",
    "            style_features = all_features[style_layer].clone()\n",
    "            style_features = style_features.view(style_features.size(0), -1).cuda() # Flatten style features\n",
    "            \n",
    "            style_output = style_classifier(style_features)\n",
    "            \n",
    "            predictions = torch.max(style_output, 1)[1]\n",
    "            predictions = predictions.view(predictions.size(0))\n",
    "            start = batch_counter * 50\n",
    "            all_predictions[start:start + 50] = predictions.data.cpu().numpy()\n",
    "            all_labels[start:start + 50] = Y\n",
    "            \n",
    "            batch_counter += 1\n",
    "            if batch_counter == n_batches:\n",
    "                raise(StopIteration)\n",
    "                      \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    return all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_style_confusion_matrix(n_categories, n_batches, atype, object_to_artists):\n",
    "    confusion = torch.zeros(n_categories, n_categories)\n",
    "    \n",
    "    predictions, labels = generate_style_predictions(n_batches, atype, object_to_artists)\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        prediction = predictions[i]\n",
    "        label = labels[i]\n",
    "        confusion[label][prediction] += 1\n",
    "    \n",
    "    \n",
    "    # Normalize by dividing every row by its sum\n",
    "    for i in range(n_categories):\n",
    "        confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "    # Set up plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion.numpy())\n",
    "    fig.colorbar(cax, cmap='jet')\n",
    "\n",
    "    # Set up axes\n",
    "    all_categories = ['Jan Luyken',\n",
    "        'George Breitner',\n",
    "        'Reinier Vinkeles',\n",
    "        'Marius Bauer',\n",
    "        'Isaac Israels',\n",
    "        'Willem Witsen',\n",
    "        'Daniel Chodowiecki',\n",
    "        'Bernard Picart',\n",
    "        'Rembrandt van Rijn',\n",
    "        'Jacob Houbraken',\n",
    "        'Antonio Tempesta',\n",
    "        'Johannes Tavenraat',\n",
    "        'Wenceslaus Hollar',\n",
    "        'Simon Fokke',\n",
    "        'Carel Cachet',\n",
    "        'Jacob de Gheyn (II)',\n",
    "        'Romeyn de Hooghe',\n",
    "        'Meissener Manufaktur',\n",
    "        'Jacques Callot',\n",
    "        'Johann Sadeler (I)',\n",
    "        'Jozef Israels',\n",
    "        'Frans Hogenberg',\n",
    "        'Crispijn van de Passe',\n",
    "        'Jan van de Velde (II)',\n",
    "        'Virgilius Solis (I)']\n",
    "    ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "    ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "    # Force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    # sphinx_gallery_thumbnail_number = 2\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAFkCAYAAAAOvG3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f7501d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_style_confusion_matrix(25, 100, 'test', object_to_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply style classifier.\n",
    "style_train_losses, style_val_losses = [], []\n",
    "for i in range(5):\n",
    "    print('Epoch: ' + str(i+1))\n",
    "    curr_style_tl, curr_style_vl = run_content_epoch(object_to_artists)\n",
    "    style_train_losses += curr_style_tl\n",
    "    style_val_losses += curr_style_vl\n",
    "    compute_content_accuracy('train', object_to_artists)\n",
    "    compute_content_accuracy('test', object_to_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrain CNN and test classification.\n",
    "new_classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Conv2d(512, num_artists, kernel_size=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(13)\n",
    ").cuda()\n",
    "\n",
    "cnn.classifier = new_classifier\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "    \n",
    "print('Starting Retraining Cycle.')\n",
    "retrain_content_train_losses, retrain_content_val_losses = [], []\n",
    "for i in range(5):\n",
    "    curr_content_tl, curr_content_vl = run_content_retrain_epoch(object_to_artists)\n",
    "    retrain_content_train_losses += curr_content_tl\n",
    "    retrain_content_val_losses += curr_content_vl\n",
    "    \n",
    "    compute_content_accuracy('train', object_to_artists)\n",
    "    compute_content_accuracy('test', object_to_artists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
